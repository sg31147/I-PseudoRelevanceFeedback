{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53826/776534087.py:46: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../../configs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Device: cpu'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Device: cpu'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'CUDA_VISIBLE_DEVICES: [6]'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'CUDA_VISIBLE_DEVICES: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from rich.pretty import pprint\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "from src.data.data_pipeline import data_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n",
    "\n",
    "LOGGER = logging.getLogger(name='test')\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "def deterministic() -> None:\n",
    "    \"\"\"Run experiment deterministically. There will still be some randomness in the backward pass of the model.\"\"\"\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "    import torch\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "# Clear the global Hydra instance\n",
    "GlobalHydra.instance().clear()\n",
    "#Load configuration\n",
    "\n",
    "initialize(config_path=\"../../configs\")\n",
    "\n",
    "\n",
    "cfg = compose(config_name=\"config\",\n",
    "              overrides=[\"experiment=mimiciv_icd10/vanillaconv.yaml\",\n",
    "                         \"trainer.validate_on_training_data=false\"\n",
    "                         #\"callbacks=no_wandb\",\n",
    "                         #\"load_model=./experiments/t1dbhfub\",\n",
    "                         #\"trainer.epochs=1\"\n",
    "                         ])\n",
    "\n",
    "\n",
    "if cfg.deterministic:\n",
    "    deterministic()\n",
    "else:\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU is available\")\n",
    "        print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU is not available\")\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "     \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")\n",
    "pprint(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1337, 'deterministic': False, 'gpu': [6], 'name': None, 'debug': False, 'load_model': None, 'data': {'dir': 'files/data/mimiciv_icd10', 'data_filename': 'mimiciv_icd10.feather', 'split_filename': 'mimiciv_icd10_split.feather', 'code_column_names': ['icd10_diag', 'icd10_proc'], 'max_length': 4000}, 'dataset': {'name': 'BaseDataset', 'configs': {}}, 'dataloader': {'max_batch_size': 128, 'batch_size': 8, 'num_workers': 0, 'drop_last': True, 'pin_memory': False, 'batch_sampler': {'name': 'BySequenceLengthSampler', 'configs': {'bucket_boundaries': [400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2600, 3000, 4000]}}}, 'model': {'name': 'VanillaConv', 'configs': {'embed_dropout': 0, 'num_filters': 500, 'kernel_size': 4}}, 'text_encoder': {'name': 'Word2Vec', 'file_name': 'word2vec_full.model', 'load_model': True, 'configs': {'min_document_count': 3, 'model_configs': {'vector_size': 100, 'min_count': 0, 'workers': -1, 'epochs': 5}}}, 'trainer': {'epochs': 20, 'validate_on_training_data': False, 'print_metrics': False, 'use_amp': True, 'threshold_tuning': True}, 'optimizer': {'name': 'AdamW', 'configs': {'lr': 0.001, 'weight_decay': 1e-05}}, 'lr_scheduler': {'name': 'linear', 'configs': {'num_warmup_steps': 2000}}, 'label_transform': {'name': 'OneHotEncoder', 'configs': {}}, 'text_transform': {'name': 'TokenSequence', 'configs': {'min_frequency': 3}}, 'metrics': [{'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5}}, {'name': 'Precision_K', 'configs': {'k': 1}}, {'name': 'Precision_K', 'configs': {'k': 5}}, {'name': 'Precision_K', 'configs': {'k': 8}}, {'name': 'Precision_K', 'configs': {'k': 15}}, {'name': 'Recall_K', 'configs': {'k': 10}}, {'name': 'Recall_K', 'configs': {'k': 15}}, {'name': 'MeanAveragePrecision', 'configs': {}}, {'name': 'PrecisionAtRecall', 'configs': {}}, {'name': 'AUC', 'configs': {'average': 'micro'}}, {'name': 'AUC', 'configs': {'average': 'macro'}}, {'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 1, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 8, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 10, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'MeanAveragePrecision', 'configs': {'filter_codes': False}}, {'name': 'PrecisionAtRecall', 'configs': {'filter_codes': False}}, {'name': 'AUC', 'configs': {'average': 'micro', 'filter_codes': False}}, {'name': 'LossMetric', 'configs': {}}], 'lookup': {'code_description': {'code_desc_path': None, 'code_column': None, 'desc_column': None}}, 'callbacks': [{'name': 'WandbCallback', 'configs': {'project': 'automatic-medical-coding', 'entity': None}}, {'name': 'SaveBestModelCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'map'}}, {'name': 'EarlyStoppingCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'map', 'patience': 6}}], 'data.max_length': 4000}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พูดถึง vaex\n",
    "\n",
    "'split_filename': 'mimiciv_icd10_split.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_pipeline(config=cfg.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set unsupervise train wordembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed already exist\n"
     ]
    }
   ],
   "source": [
    "text_encoder = get_text_encoder(\n",
    "    config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรงนี้เปลี่ยน target เป็น int นะ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_transform = get_transform(\n",
    "    config=cfg.label_transform,\n",
    "    targets=data.all_targets,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set TokenSequence, HuggingFaceTokenizer, BOW แต่งเติมส่วนของ padding unknow ให้เรียบร้อย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_transform = get_transform(\n",
    "    config=cfg.text_transform,\n",
    "    texts=data.get_train_documents,\n",
    "    text_encoder=text_encoder,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform text จริง โดยมองเป็น batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.truncate_text(cfg.data.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming text...: 100%|██████████| 31/31 [00:01<00:00, 17.68it/s]\n",
      "Collecting results...: 100%|██████████| 31/31 [00:00<00:00, 2755.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#transform token=>index ตัวเลข เด๋ว train จะถูกผลักออกเป็น vector \n",
    "data.transform_text(text_transform.batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target มีทำ map กลับเป็น int ไว้เลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_classes_per_example': 15.65479481182224,\n",
      " 'average_tokens_per_example': 1596.879217847855,\n",
      " 'num_classes': 7942,\n",
      " 'num_examples': 122278,\n",
      " 'num_test_classes': 7937,\n",
      " 'num_test_examples': 21265,\n",
      " 'num_train_classes': 7938,\n",
      " 'num_train_examples': 76933,\n",
      " 'num_train_tokens': 122848593,\n",
      " 'num_val_classes': 7932,\n",
      " 'num_val_examples': 24080,\n",
      " 'pad_index': 0,\n",
      " 'vocab_size': 62792}\n"
     ]
    }
   ],
   "source": [
    "lookups = get_lookups(\n",
    "    config=cfg.lookup,\n",
    "    data=data,\n",
    "    label_transform=label_transform,\n",
    "    text_transform=text_transform,\n",
    ")\n",
    "\n",
    "# print data info\n",
    "pprint(lookups.data_info)\n",
    "# pprint(lookups.data_info[\"num_classes\"] == len(lookups.code_system2code_indices['icd10_diag'])+len(lookups.code_system2code_indices['icd10_proc']))\n",
    "\n",
    "\n",
    "#สังเกตแค่่ train เท่านั้นหากเราพยายามเปลียน input เพื่อทดสอบ n น้อยๆ ให้ run model ผ่าน ตอน val / test ถูกล็อคไว้หมดแล้ว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ระบุโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VanillaConv(\n",
       "  (embed_drop): Dropout(p=0, inplace=False)\n",
       "  (embed): Embedding(62792, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 500, kernel_size=(4,), stride=(1,))\n",
       "  (fc): Linear(in_features=500, out_features=7942, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(\n",
    "    config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จัดเตรียม datasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating examples train: 100%|██████████| 76933/76933 [00:05<00:00, 13665.72it/s]\n",
      "Creating examples val: 100%|██████████| 24080/24080 [00:01<00:00, 12908.44it/s]\n",
      "Creating examples test: 100%|██████████| 21265/21265 [00:01<00:00, 13803.92it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets(\n",
    "    config=cfg.dataset,\n",
    "    data=data,\n",
    "    text_transform=text_transform,\n",
    "    label_transform=label_transform,\n",
    "    lookups=lookups,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สามารถปรับ batch Optimize ได้ตรงนี้เลย ตรงนี้เป็นการบังคับเฉพาะให้เฉพาะ train เท่านั้น ถูกควบคุมโดย cfg.dataloader.name\n",
    "\n",
    "set loader มีทั้ง train train_val test val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Train batch size: 8'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Train batch size: 8'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: drop_last=True, dropping last non batch-size batch in every bucket ... \n"
     ]
    }
   ],
   "source": [
    "#ตรงนี้เตรียม batch ให้เรียบร้อยแล้วหละ เดิม #dataset ยังไม่ทำเป็น batch นะ \n",
    "dataloaders = get_dataloaders(config=cfg.dataloader, datasets_dict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 1e-05\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = get_optimizer(config=cfg.optimizer, model=model)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรื่องของ batchsize ตำนวนหา gradient กรณี accumulate_grad_batches > 1 แสดงว่ายังไม่ปรับ grad ทันที & Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_grad_batches = int(\n",
    "    max(cfg.dataloader.batch_size / cfg.dataloader.max_batch_size, 1)\n",
    ")\n",
    "num_training_steps = (\n",
    "    math.ceil(len(dataloaders[\"train\"]) / accumulate_grad_batches)\n",
    "    * cfg.trainer.epochs\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(\n",
    "    config=cfg.lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_names: list[str] = [\"train\", \"train_val\", \"val\", \"test\"],\n",
    "\n",
    "splits_with_multiple_code_systems: set[str] = {\"train_val\", \"val\", \"test\"},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'train': {'all': <src.metrics.MetricCollection at 0x7f9ddc373520>},\n",
       "             'train_val': {'all': <src.metrics.MetricCollection at 0x7f9ddc373730>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f9ddc3d4190>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f9ddc3d4910>},\n",
       "             'val': {'all': <src.metrics.MetricCollection at 0x7f9ddc3d5090>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f9ddc3d5810>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f9ddc3d5f90>},\n",
       "             'test': {'all': <src.metrics.MetricCollection at 0x7f9ddc3d67a0>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f9ddc3d6f20>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f9ddc3d76a0>}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code_system2code_indices => diag proc (ทั้งหมดเลยนะไม่แยก train test)\n",
    "#split2code_indices =>  train train_val val test\n",
    "metric_collections = get_metric_collections(\n",
    "    config=cfg.metrics,\n",
    "    number_of_classes=lookups.data_info[\"num_classes\"],\n",
    "    code_system2code_indices=lookups.code_system2code_indices, # รวมทั้งหมดที่เป็น label diag และ label proc\n",
    "    split2code_indices=lookups.split2code_indices, # label classs แต่ละ กกลุ่มที่แบ่งไป ตาม \n",
    ")\n",
    "metric_collections\n",
    "\n",
    "#ข้างในมี แต่ index ล้วนๆเลยนะ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name: WandbCallback\n",
    "\n",
    "- name: SaveBestModelCallback\n",
    "\n",
    "- name: EarlyStoppingCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.trainer.callbacks.WandbCallback at 0x7f9ddc3ec5e0>,\n",
       " <src.trainer.callbacks.SaveBestModelCallback at 0x7f9ddc3ec610>,\n",
       " <src.trainer.callbacks.EarlyStoppingCallback at 0x7f9ddc3ec700>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = get_callbacks(config=cfg.callbacks)\n",
    "callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 1337, 'deterministic': False, 'gpu': [6], 'name': None, 'debug': False, 'load_model': None, 'data': {'dir': 'files/data/mimiciv_icd10', 'data_filename': 'mimiciv_icd10.feather', 'split_filename': 'mimiciv_icd10_split.feather', 'code_column_names': ['icd10_diag', 'icd10_proc'], 'max_length': 4000}, 'dataset': {'name': 'BaseDataset', 'configs': {}}, 'dataloader': {'max_batch_size': 128, 'batch_size': 8, 'num_workers': 0, 'drop_last': True, 'pin_memory': False, 'batch_sampler': {'name': 'BySequenceLengthSampler', 'configs': {'bucket_boundaries': [400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2600, 3000, 4000]}}}, 'model': {'name': 'VanillaConv', 'configs': {'embed_dropout': 0, 'num_filters': 500, 'kernel_size': 4}}, 'text_encoder': {'name': 'Word2Vec', 'file_name': 'word2vec_full.model', 'load_model': True, 'configs': {'min_document_count': 3, 'model_configs': {'vector_size': 100, 'min_count': 0, 'workers': -1, 'epochs': 5}}}, 'trainer': {'epochs': 20, 'validate_on_training_data': False, 'print_metrics': False, 'use_amp': True, 'threshold_tuning': True}, 'optimizer': {'name': 'AdamW', 'configs': {'lr': 0.001, 'weight_decay': 1e-05}}, 'lr_scheduler': {'name': 'linear', 'configs': {'num_warmup_steps': 2000}}, 'label_transform': {'name': 'OneHotEncoder', 'configs': {}}, 'text_transform': {'name': 'TokenSequence', 'configs': {'min_frequency': 3}}, 'metrics': [{'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5}}, {'name': 'Precision_K', 'configs': {'k': 1}}, {'name': 'Precision_K', 'configs': {'k': 5}}, {'name': 'Precision_K', 'configs': {'k': 8}}, {'name': 'Precision_K', 'configs': {'k': 15}}, {'name': 'Recall_K', 'configs': {'k': 10}}, {'name': 'Recall_K', 'configs': {'k': 15}}, {'name': 'MeanAveragePrecision', 'configs': {}}, {'name': 'PrecisionAtRecall', 'configs': {}}, {'name': 'AUC', 'configs': {'average': 'micro'}}, {'name': 'AUC', 'configs': {'average': 'macro'}}, {'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 1, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 8, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 10, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'MeanAveragePrecision', 'configs': {'filter_codes': False}}, {'name': 'PrecisionAtRecall', 'configs': {'filter_codes': False}}, {'name': 'AUC', 'configs': {'average': 'micro', 'filter_codes': False}}, {'name': 'LossMetric', 'configs': {}}], 'lookup': {'code_description': {'code_desc_path': None, 'code_column': None, 'desc_column': None}}, 'callbacks': [{'name': 'WandbCallback', 'configs': {'project': 'automatic-medical-coding', 'entity': None}}, {'name': 'SaveBestModelCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'map'}}, {'name': 'EarlyStoppingCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'map', 'patience': 6}}], 'data.max_length': 4000}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Accumulating gradients over 1 batch(es).'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Accumulating gradients over 1 batch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mes\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main/src/trainer/trainer.py:56: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  #ไฟล์นี้บรรจุแค่ configfile เอง มันมีการถูกบันทึกเหมือนกลไก wandb\n",
      "/root/python/myenv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmpb597hsq1'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/tmp/tmpb597hsq1'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrxsu08560194\u001b[0m (\u001b[33mICD-10\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./experiments/wandb/run-20250223_123930-xela8cvk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ICD-10/automatic-medical-coding/runs/xela8cvk' target=\"_blank\">rural-frost-542</a></strong> to <a href='https://wandb.ai/ICD-10/automatic-medical-coding' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ICD-10/automatic-medical-coding' target=\"_blank\">https://wandb.ai/ICD-10/automatic-medical-coding</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ICD-10/automatic-medical-coding/runs/xela8cvk' target=\"_blank\">https://wandb.ai/ICD-10/automatic-medical-coding/runs/xela8cvk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiments/xela8cvk\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=cfg,\n",
    "    data=datasets,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataloaders=dataloaders,\n",
    "    metric_collections=metric_collections, # metric มี 4 กลุ่ม ตอน ใช้ metric จะแยกกล่มใครกล่มมั่นไปแล้ว\n",
    "    callbacks=callbacks,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    lookups=lookups,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train  ตรงส่วนนี้จะระบุว่าไฟล์ข้อมูลทั้งหมดจะถูกวางไว้ที่ไหนเลย\n",
    "\n",
    "ตอน validate จะสืบหา f1 ที่ดีที่สด "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Training:   0%|          | 0/9616 [00:00<?, ?it/s]/root/python/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch: 0 | Training:  97%|█████████▋| 9284/9616 [13:41<00:25, 12.93it/s]"
     ]
    }
   ],
   "source": [
    "if cfg.load_model:\n",
    "    trainer.experiment_path = Path(cfg.load_model)\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
