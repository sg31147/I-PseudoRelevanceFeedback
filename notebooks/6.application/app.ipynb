{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json \n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "import nest_asyncio\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel,Field\n",
    "from uvicorn import Config, Server\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "import gc\n",
    "from src.utils.fun_retrieval import pseudo_relevance_feedback\n",
    "\n",
    "from src.settings import (\n",
    "    DOWNLOAD_DIRECTORY_MIMICIV\n",
    ")\n",
    "\n",
    "\n",
    "from prepare_data.utils import (\n",
    "    TextPreprocessor,\n",
    "    preprocess_documents,\n",
    "    load_gz_file_into_df,\n",
    "    ID_COLUMN, SUBJECT_ID_COLUMN, TARGET_COLUMN, TEXT_COLUMN\n",
    "    \n",
    ")\n",
    "from src.data.data_pipeline import data_predict_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n",
    "from src.settings import best_runs\n",
    "\n",
    "LOGGER = logging.getLogger(name='test')\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "def deterministic() -> None:\n",
    "    \"\"\"Run experiment deterministically. There will still be some randomness in the backward pass of the model.\"\"\"\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "    import torch\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "# Clear the global Hydra instance\n",
    "GlobalHydra.instance().clear()\n",
    "#Load configuration\n",
    "\n",
    "initialize(config_path=\"../../configs\")\n",
    "#caml multi_res_conv vanillaconv vanillagru laat plm_icd\n",
    "cfg = compose(config_name=\"config\",\n",
    "              overrides=[\"experiment=mimiciv_icd10/plm_icd.yaml\",\n",
    "                         \"callbacks=no_wandb\",\n",
    "                         \"load_model=null\",\"trainer.epochs=0\"]\n",
    "                        )\n",
    "\n",
    "\n",
    "\n",
    "cfg.load_model = best_runs[cfg.model.name]\n",
    "\n",
    "\n",
    "if cfg.deterministic:\n",
    "    deterministic()\n",
    "else:\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU is available\")\n",
    "        print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU is not available\")\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "\n",
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "torch.set_num_threads(os.cpu_count())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping Definition\n",
    "download_dir = Path(DOWNLOAD_DIRECTORY_MIMICIV)\n",
    "\n",
    "d_icd_procedures = load_gz_file_into_df(\n",
    "    download_dir / \"hosp/d_icd_procedures.csv.gz\", dtype={\"icd_code\": str}\n",
    ")\n",
    "d_icd_procedures=d_icd_procedures[d_icd_procedures['icd_version']==10]\n",
    "d_icd_diagnoses = load_gz_file_into_df(\n",
    "    download_dir / \"hosp/d_icd_diagnoses.csv.gz\", dtype={\"icd_code\": str}\n",
    ")\n",
    "d_icd_diagnoses=d_icd_diagnoses[d_icd_diagnoses['icd_version']==10]\n",
    "d_icd_diagnoses = d_icd_diagnoses[['icd_code', 'long_title']].set_index('icd_code')['long_title'].to_dict()\n",
    "d_icd_procedures = d_icd_procedures[['icd_code', 'long_title']].set_index('icd_code')['long_title'].to_dict()\n",
    "d_icd={**d_icd_diagnoses,**d_icd_procedures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = pd.read_feather(best_runs[cfg.model.name] + '/train_targets.feather')\n",
    "train_targets = torch.tensor(train_targets.values, dtype=torch.float32, device=device)\n",
    "print('load train_targets finish')\n",
    "\n",
    "# val_targets = pd.read_feather(best_runs[cfg.model.name] + '/val_targets.feather')\n",
    "# val_targets = torch.tensor(val_targets.values, dtype=torch.float32, device=device)\n",
    "# print('load val_targets finish')\n",
    "\n",
    "\n",
    "# test_targets = pd.read_feather(best_runs[cfg.model.name] + '/test_targets.feather')\n",
    "# test_targets = torch.tensor(test_targets.values, dtype=torch.float32, device=device)\n",
    "# print('load test_targets finish')\n",
    "\n",
    "\n",
    "# Merge all into retrieve\n",
    "retrieve = torch.cat([train_targets,\n",
    "                        #val_targets,\n",
    "                        #test_targets\n",
    "                    ], dim=0)\n",
    "del train_targets\n",
    "#del val_targets\n",
    "print('merge finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your JSON file\n",
    "file_path = best_runs[cfg.model.name] +'/target2index.json'\n",
    "\n",
    "# Open the file and load the JSON data\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "token2index = {token: index for index, token in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Pydantic model for the data structure\n",
    "\n",
    "class TestDataModel(BaseModel):\n",
    "    id: List[int]\n",
    "    text: List[str]\n",
    "    target: List[List[str]]\n",
    "    split: str\n",
    "    Task:str\n",
    "    iteration: int = Field(2, ge=0, le=10, description=\"iteration must be between 0 and 10\") \n",
    "    alpha: float = Field(1, ge=0, le=1, description=\"alpha must be between 0 and 1\")\n",
    "    beta: float = Field(0.1, ge=0, le=1, description=\"beta must be between 0 and 1\")\n",
    "    TopKSelection: int = Field(10, ge=1, le=50, description=\"TopKSelection must be between 10 and 15\")\n",
    "    gramma: float = Field(0.1, ge=0, le=1, description=\"gramma must be between 0 and 1\")\n",
    "    CosSim_Thresh: int = Field(10, ge=1, le=50, description=\"CosSim_Thresh must be between 0 and 50\")\n",
    "    Precisionk: int = Field(5, ge=1, le=15, description=\"precision@k must be between 1 and 15\")\n",
    "\n",
    "# Apply nest_asyncio to allow FastAPI to run within Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Define the FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/mapping/\")\n",
    "async def mapping():\n",
    "    return {\n",
    "        \"status\": \"load mapping successfully\",\n",
    "        \"data\": {\n",
    "            values: d_icd[values.replace(\".\", \"\")] \n",
    "                           for values in token2index.values() \n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# Create a POST route for receiving and validating the data structure\n",
    "@app.post(\"/predict/\")\n",
    "async def predict(Testdata: TestDataModel):\n",
    "    \n",
    "    data = Testdata.model_dump(by_alias=True)\n",
    "    data = pd.DataFrame(data).rename(columns={'id': ID_COLUMN})\n",
    "    \n",
    "    #preprocesss\n",
    "    preprocessor = TextPreprocessor(\n",
    "                lower=True,\n",
    "                remove_special_characters_mullenbach=True,\n",
    "                remove_special_characters=False,\n",
    "                remove_digits=True,\n",
    "                remove_accents=False,\n",
    "                remove_brackets=False,\n",
    "                convert_danish_characters=False,\n",
    "            )\n",
    "\n",
    "    data=preprocess_documents(df=data, preprocessor=preprocessor)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Here, the validated data can be processed as needed\n",
    "    data = data_predict_pipeline(config=cfg.data,data=data)\n",
    "\n",
    "    text_encoder = get_text_encoder(\n",
    "        config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    "    )\n",
    "    label_transform = get_transform(\n",
    "        config=cfg.label_transform,\n",
    "        targets=data.all_targets,\n",
    "        load_transform_path=cfg.load_model,\n",
    "    )\n",
    "    text_transform = get_transform(\n",
    "        config=cfg.text_transform,\n",
    "        texts=data.get_train_documents,\n",
    "        text_encoder=text_encoder,\n",
    "        load_transform_path=cfg.load_model,\n",
    "    )\n",
    "    \n",
    "    data.truncate_text(cfg.data.max_length)\n",
    "    data.transform_text(text_transform.batch_transform)\n",
    "    lookups = get_lookups(\n",
    "        config=cfg.lookup,\n",
    "        data=data,\n",
    "        label_transform=label_transform,\n",
    "        text_transform=text_transform,\n",
    "    )\n",
    "   \n",
    "    model = get_model(\n",
    "        config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder\n",
    "    ).to(device)\n",
    "    \n",
    "    datasets = get_datasets(\n",
    "        config=cfg.dataset,\n",
    "        data=data,\n",
    "        text_transform=text_transform,\n",
    "        label_transform=label_transform,\n",
    "        lookups=lookups,\n",
    "    )\n",
    "    \n",
    "    dataloaders = get_dataloaders(config=cfg.dataloader, datasets_dict=datasets)\n",
    "    \n",
    "    optimizer = get_optimizer(config=cfg.optimizer, model=model)\n",
    "    accumulate_grad_batches = int(\n",
    "        max(cfg.dataloader.batch_size / cfg.dataloader.max_batch_size, 1)\n",
    "    )\n",
    "    \n",
    "    num_training_steps = (\n",
    "        math.ceil(len(dataloaders[\"train\"]) / accumulate_grad_batches)\n",
    "        * cfg.trainer.epochs\n",
    "    )\n",
    "    \n",
    "    lr_scheduler = get_lr_scheduler(\n",
    "        config=cfg.lr_scheduler,\n",
    "        optimizer=optimizer,\n",
    "        num_training_steps=num_training_steps,\n",
    "    )\n",
    "    metric_collections = get_metric_collections(\n",
    "        config=cfg.metrics,\n",
    "        number_of_classes=lookups.data_info[\"num_classes\"],\n",
    "        code_system2code_indices=lookups.code_system2code_indices, # รวมทั้งหมดที่เป็น label diag และ label proc\n",
    "        split2code_indices=lookups.split2code_indices, # label classs แต่ละ กกลุ่มที่แบ่งไป ตาม \n",
    "    )\n",
    "    callbacks = get_callbacks(config=cfg.callbacks)\n",
    "\n",
    "\n",
    "    pred = Trainer(\n",
    "        config=cfg,\n",
    "        data=data,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        dataloaders=dataloaders,\n",
    "        metric_collections=metric_collections, # metric มี 4 กลุ่ม ตอน ใช้ metric จะแยกกล่มใครกล่มมั่นไปแล้ว\n",
    "        callbacks=callbacks,\n",
    "        lr_scheduler=lr_scheduler,\n",
    "        lookups=lookups,\n",
    "        accumulate_grad_batches=accumulate_grad_batches,\n",
    "        experiment_path = Path(cfg.load_model) # ไว้สำหรับ eval \n",
    "    ).to(device)\n",
    "\n",
    "    if cfg.load_model:\n",
    "        pred.experiment_path = Path(cfg.load_model)\n",
    "    predict=pred.fit(predict=True)\n",
    "    \n",
    "    ids, logits, targets = predict[\"ids\"], predict[\"logits\"], predict[\"targets\"]\n",
    "\n",
    "\n",
    "\n",
    "    Task=Testdata.Task\n",
    "    alpha=Testdata.alpha\n",
    "    beta=Testdata.beta\n",
    "    gramma=Testdata.gramma\n",
    "    TopKSelection=Testdata.TopKSelection\n",
    "    Precisionk = Testdata.Precisionk\n",
    "    consine_threshold=Testdata.CosSim_Thresh\n",
    "    for i in range(1,Testdata.iteration):\n",
    "\n",
    "        logits=pseudo_relevance_feedback(retrieve, logits, TopKSelection=TopKSelection,CosSim_Thresh=consine_threshold,\n",
    "                                                alpha=alpha, beta=beta, gramma=gramma, \n",
    "                                                chunk_size_b=80000)\n",
    " \n",
    "\n",
    "  \n",
    "\n",
    "    predict = {id_: {\"logits\": logit, \"targets\": target} for id_, logit, target in zip(ids, logits, targets)}\n",
    "\n",
    "    if Task == \"Ranking\":\n",
    "        result = {\n",
    "            ids.item(): {\n",
    "                \"id\": ids.item(),\n",
    "                \"result\": {\n",
    "                    token2index[idx]: f'{d_icd[token2index[idx].replace(\".\", \"\")]} ({prob})'\n",
    "\n",
    "                    for idx, prob in zip(\n",
    "                        logits[\"logits\"].topk(Precisionk).indices.tolist(),\n",
    "                        logits[\"logits\"].topk(Precisionk).values.tolist()\n",
    "                    )\n",
    "                },\n",
    "                #\"target\": [token2index[idx] for idx in (data_entry[\"target\"] == 1).nonzero(as_tuple=True)[0].tolist()],\n",
    "                \"match_percentage_topk\": round(\n",
    "                sum(1 for idx in logits[\"logits\"].topk(Precisionk).indices.tolist() if token2index[idx] in [\n",
    "                    token2index[idx] for idx in (logits[\"targets\"] == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "                ]) / Precisionk * 100, 2),\n",
    "            }\n",
    "            for ids, logits in predict.items()\n",
    "        }\n",
    "    else:\n",
    "        result = {\n",
    "            ids.item(): {\n",
    "                \"id\": ids.item(),\n",
    "                \"result\": {\n",
    "                    token2index[idx]: f'{d_icd[token2index[idx].replace(\".\", \"\")]} ({prob})'\n",
    "                    for idx, prob in zip(\n",
    "                        (logits[\"logits\"] > pred.best_db).nonzero(as_tuple=True)[0].tolist(),\n",
    "                        logits[\"logits\"][logits[\"logits\"] > pred.best_db].tolist()\n",
    "                    )\n",
    "                },\n",
    "                #\"target\": [token2index[idx] for idx in (data_entry[\"target\"] == 1).nonzero(as_tuple=True)[0].tolist()],\n",
    "                \"match_percentage_classification\": round(\n",
    "                sum(1 for idx in (logits[\"logits\"] > pred.best_db).nonzero(as_tuple=True)[0].tolist() if token2index[idx] in [\n",
    "                    token2index[idx] for idx in (logits[\"targets\"] == 1).nonzero(as_tuple=True)[0].tolist()\n",
    "                ]) / len((logits[\"logits\"] > pred.best_db).nonzero(as_tuple=True)[0].tolist()) * 100, 2),\n",
    "\n",
    "            }\n",
    "            for ids, logits in predict.items()\n",
    "        }\n",
    "    \n",
    "    del predict,pred,metric_collections,lr_scheduler,num_training_steps,accumulate_grad_batches,optimizer,dataloaders,datasets,callbacks,data,text_encoder,label_transform,text_transform,lookups,model\n",
    "    gc.collect()\n",
    "    return {\"status\": \"Predict successfully\", \"data\": result}\n",
    "\n",
    "# Run the app\n",
    "config = Config(app=app, host=\"0.0.0.0\", port=8081)\n",
    "server = Server(config)\n",
    "server.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
