{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import logging\n",
    "import random\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from prepare_data.utils import (\n",
    "    TextPreprocessor,\n",
    "    load_gz_file_into_df,\n",
    "    preprocess_documents,\n",
    "    reformat_code_dataframe,\n",
    "    reformat_icd,\n",
    ")\n",
    "from src.settings import (\n",
    "    DATA_DIRECTORY_MIMICIV_ICD10,\n",
    "    DOWNLOAD_DIRECTORY_MIMICIV,\n",
    "    DOWNLOAD_DIRECTORY_MIMICIV_NOTE,\n",
    "    ID_COLUMN,\n",
    "    SUBJECT_ID_COLUMN,\n",
    "    TARGET_COLUMN,\n",
    "    TEXT_COLUMN,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def filter_codes(df: pd.DataFrame, columns: list[str], min_count: int) -> pd.DataFrame:\n",
    "    \"\"\"Filter the codes dataframe to only include codes that appear at least min_count times\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The codes dataframe\n",
    "        col (str): The column name of the codes\n",
    "        min_count (int): The minimum number of times a code must appear\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The filtered codes dataframe\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        code_counts = Counter([code for codes in df[col] for code in codes])\n",
    "        codes_to_keep = set(\n",
    "            code for code, count in code_counts.items() if count >= min_count\n",
    "        )\n",
    "        df[col] = df[col].apply(lambda x: [code for code in x if code in codes_to_keep])\n",
    "        print(f\"Number of unique codes in {col} before filtering: {len(code_counts)}\")\n",
    "        print(f\"Number of unique codes in {col} after filtering: {len(codes_to_keep)}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_codes_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse the codes dataframe\"\"\"\n",
    "    df = df.rename(columns={\"hadm_id\": ID_COLUMN, \"subject_id\": SUBJECT_ID_COLUMN})\n",
    "    df = df.dropna(subset=[\"icd_code\"])\n",
    "    df = df.drop_duplicates(subset=[ID_COLUMN, \"icd_code\"])\n",
    "    df = (\n",
    "        df.groupby([SUBJECT_ID_COLUMN, ID_COLUMN, \"icd_version\"])\n",
    "        .apply(partial(reformat_code_dataframe, col=\"icd_code\"))\n",
    "        .reset_index()\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def parse_notes_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Parse the notes dataframe\"\"\"\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"hadm_id\": ID_COLUMN,\n",
    "            \"subject_id\": SUBJECT_ID_COLUMN,\n",
    "            \"text\": TEXT_COLUMN,\n",
    "        }\n",
    "    )\n",
    "    df = df.dropna(subset=[TEXT_COLUMN])\n",
    "    df = df.drop_duplicates(subset=[ID_COLUMN, TEXT_COLUMN])\n",
    "    return df\n",
    "\n",
    "\n",
    "MIN_TARGET_COUNT = 10  # Minimum number of times a code must appear to be included\n",
    "preprocessor = TextPreprocessor(\n",
    "    lower=True,\n",
    "    remove_special_characters_mullenbach=True,\n",
    "    remove_special_characters=False,\n",
    "    remove_digits=True,\n",
    "    remove_accents=False,\n",
    "    remove_brackets=False,\n",
    "    convert_danish_characters=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:discharge.feather already exists, loading data from discharge.feather into a pandas dataframe.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(10)\n",
    "\n",
    "# The dataset requires a Licence in physionet. Once it is obtained, download the dataset with the following command in the terminal:\n",
    "# wget -r -N -c -np --user <your_physionet_user_name> --ask-password https://physionet.org/files/mimiciii/1.4/\n",
    "# Change the path of DOWNLOAD_DIRECTORY to the path where you downloaded mimiciii\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "download_dir_note = Path(DOWNLOAD_DIRECTORY_MIMICIV_NOTE)\n",
    "download_dir = Path(DOWNLOAD_DIRECTORY_MIMICIV)\n",
    "\n",
    "\n",
    "output_dir_icd10 = Path(DATA_DIRECTORY_MIMICIV_ICD10)\n",
    "output_dir_icd10.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load the data\n",
    "mimic_notes = load_gz_file_into_df(download_dir_note / \"note/discharge.csv.gz\")\n",
    "mimic_proc = load_gz_file_into_df(\n",
    "    download_dir / \"hosp/procedures_icd.csv.gz\", dtype={\"icd_code\": str}\n",
    ")\n",
    "mimic_diag = load_gz_file_into_df(\n",
    "    download_dir / \"hosp/diagnoses_icd.csv.gz\", dtype={\"icd_code\": str}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('dataset/mimiciv/hosp/diagnoses_icd.csv.gz')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_dir_note / \"hosp/diagnoses_icd.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_icd_codes(df, is_diag):\n",
    "    df[\"icd_code\"] = df.apply(\n",
    "        lambda row: reformat_icd(\n",
    "            code=row[\"icd_code\"], version=row[\"icd_version\"], is_diag=is_diag\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Use multiprocessing to process the diagnosis and procedure dataframes in parallel\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    mimic_proc, mimic_diag = pool.starmap(\n",
    "        process_icd_codes, [(mimic_proc, False), (mimic_diag, True)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_113447/1516929757.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(partial(reformat_code_dataframe, col=\"icd_code\"))\n",
      "/tmp/ipykernel_113447/1516929757.py:60: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(partial(reformat_code_dataframe, col=\"icd_code\"))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of tasks to be processed in parallel (functions and corresponding arguments)\n",
    "tasks = [\n",
    "    (parse_codes_dataframe, mimic_proc),\n",
    "    (parse_codes_dataframe, mimic_diag),\n",
    "    (parse_notes_dataframe, mimic_notes)\n",
    "]\n",
    "\n",
    "# Function to unpack and run the function with the provided arguments\n",
    "def process_task(task):\n",
    "    func, df = task\n",
    "    return func(df)\n",
    "\n",
    "# Use multiprocessing to process the dataframes in parallel\n",
    "with mp.Pool(mp.cpu_count()) as pool:\n",
    "    mimic_proc, mimic_diag, mimic_notes  = pool.map(process_task, tasks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIMIC_ICD10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique codes in icd10_proc before filtering: 9942\n",
      "Number of unique codes in icd10_proc after filtering: 2139\n",
      "Number of unique codes in icd10_diag before filtering: 16156\n",
      "Number of unique codes in icd10_diag after filtering: 5803\n"
     ]
    }
   ],
   "source": [
    "mimic_proc_10 = mimic_proc[mimic_proc[\"icd_version\"] == 10]\n",
    "mimic_proc_10 = mimic_proc_10.rename(columns={\"icd_code\": \"icd10_proc\"})\n",
    "mimic_diag_10 = mimic_diag[mimic_diag[\"icd_version\"] == 10]\n",
    "mimic_diag_10 = mimic_diag_10.rename(columns={\"icd_code\": \"icd10_diag\"})\n",
    "mimiciv_10 = mimic_notes.merge(\n",
    "    mimic_proc_10[[ID_COLUMN, \"icd10_proc\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "mimiciv_10 = mimiciv_10.merge(\n",
    "    mimic_diag_10[[ID_COLUMN, \"icd10_diag\"]], on=ID_COLUMN, how=\"left\"\n",
    ")\n",
    "\n",
    "# remove notes with no codes\n",
    "mimiciv_10 = mimiciv_10.dropna(subset=[\"icd10_proc\", \"icd10_diag\"], how=\"all\")\n",
    "\n",
    "mimiciv_10[\"icd10_proc\"] = mimiciv_10[\"icd10_proc\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "mimiciv_10[\"icd10_diag\"] = mimiciv_10[\"icd10_diag\"].apply(\n",
    "    lambda x: [] if x is np.nan else x\n",
    ")\n",
    "\n",
    "mimiciv_10 = filter_codes(mimiciv_10, [\"icd10_proc\", \"icd10_diag\"], MIN_TARGET_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat proc+diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define target\n",
    "mimiciv_10[TARGET_COLUMN] = mimiciv_10[\"icd10_proc\"] + mimiciv_10[\"icd10_diag\"]\n",
    "\n",
    "# remove empty target\n",
    "mimiciv_10 = mimiciv_10[mimiciv_10[TARGET_COLUMN].apply(lambda x: len(x) > 0)]\n",
    "\n",
    "# reset index\n",
    "mimiciv_10 = mimiciv_10.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Text preprocess the notes\n",
    "mimiciv_10 = preprocess_documents(df=mimiciv_10, preprocessor=preprocessor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files to disk\n",
    "mimiciv_10.to_feather(output_dir_icd10 / \"mimiciv_icd10.feather\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
