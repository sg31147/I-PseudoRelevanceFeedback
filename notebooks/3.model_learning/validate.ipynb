{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('../../')\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-11 20:01:58.368921: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-11 20:01:58.495633: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-11 20:01:58.499535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-11 20:01:58.499549: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-11 20:01:59.251459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-11 20:01:59.251536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-11 20:01:59.251542: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/tmp/ipykernel_15253/2963314604.py:49: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../../configs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Device: cpu'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Device: cpu'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'CUDA_VISIBLE_DEVICES: [6]'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'CUDA_VISIBLE_DEVICES: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from rich.pretty import pprint\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "from src.data.data_pipeline import data_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n",
    "from src.settings import best_runs\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(name='test')\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "def deterministic() -> None:\n",
    "    \"\"\"Run experiment deterministically. There will still be some randomness in the backward pass of the model.\"\"\"\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "    import torch\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "# Clear the global Hydra instance\n",
    "GlobalHydra.instance().clear()\n",
    "#Load configuration\n",
    "\n",
    "\n",
    "initialize(config_path=\"../../configs\")\n",
    "#caml multi_res_conv vanillaconv vanillagru laat plm_icd\n",
    "cfg = compose(config_name=\"config\",\n",
    "              overrides=[\"experiment=mimiciv_icd10/plm_icd.yaml\",\n",
    "                         \"callbacks=no_wandb\",\n",
    "                         \"load_model=null\",\n",
    "                         \"trainer.epochs=0\"]\n",
    "                          )\n",
    "\n",
    "\n",
    "cfg.load_model = best_runs[cfg.model.name]\n",
    "\n",
    "if cfg.deterministic:\n",
    "    deterministic()\n",
    "else:\n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU is available\")\n",
    "        print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU is not available\")\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "\n",
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")\n",
    "pprint(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1337, 'deterministic': False, 'gpu': [6], 'name': None, 'debug': False, 'load_model': './experiments/qtsvcsd5', 'data': {'dir': 'files/data/mimiciv_icd10', 'data_filename': 'mimiciv_icd10.feather', 'split_filename': 'mimiciv_icd10_split.feather', 'code_column_names': ['icd10_diag', 'icd10_proc'], 'max_length': 4000}, 'dataset': {'name': 'BaseDataset', 'configs': {}}, 'dataloader': {'max_batch_size': 128, 'batch_size': 8, 'num_workers': 0, 'drop_last': True, 'pin_memory': False, 'batch_sampler': {'name': 'BySequenceLengthSampler', 'configs': {'bucket_boundaries': [400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2600, 3000, 4000]}}}, 'model': {'name': 'VanillaConv', 'configs': {'embed_dropout': 0, 'num_filters': 500, 'kernel_size': 4}}, 'text_encoder': {'name': 'Word2Vec', 'file_name': 'word2vec_full.model', 'load_model': True, 'configs': {'min_document_count': 3, 'model_configs': {'vector_size': 100, 'min_count': 0, 'workers': -1, 'epochs': 5}}}, 'trainer': {'epochs': 0, 'validate_on_training_data': True, 'print_metrics': False, 'use_amp': True, 'threshold_tuning': True}, 'optimizer': {'name': 'AdamW', 'configs': {'lr': 0.001, 'weight_decay': 1e-05}}, 'lr_scheduler': {'name': 'linear', 'configs': {'num_warmup_steps': 2000}}, 'label_transform': {'name': 'OneHotEncoder', 'configs': {}}, 'text_transform': {'name': 'TokenSequence', 'configs': {'min_frequency': 3}}, 'metrics': [{'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5}}, {'name': 'Precision_K', 'configs': {'k': 1}}, {'name': 'Precision_K', 'configs': {'k': 5}}, {'name': 'Precision_K', 'configs': {'k': 8}}, {'name': 'Precision_K', 'configs': {'k': 15}}, {'name': 'Recall_K', 'configs': {'k': 10}}, {'name': 'Recall_K', 'configs': {'k': 15}}, {'name': 'MeanAveragePrecision', 'configs': {}}, {'name': 'PrecisionAtRecall', 'configs': {}}, {'name': 'AUC', 'configs': {'average': 'micro'}}, {'name': 'AUC', 'configs': {'average': 'macro'}}, {'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 1, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 8, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 10, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'MeanAveragePrecision', 'configs': {'filter_codes': False}}, {'name': 'PrecisionAtRecall', 'configs': {'filter_codes': False}}, {'name': 'AUC', 'configs': {'average': 'micro', 'filter_codes': False}}, {'name': 'LossMetric', 'configs': {}}], 'lookup': {'code_description': {'code_desc_path': None, 'code_column': None, 'desc_column': None}}, 'callbacks': [{'name': 'SaveBestModelCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8'}}, {'name': 'EarlyStoppingCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8', 'patience': 10}}], 'data.max_length': 4000}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พูดถึง vaex\n",
    "\n",
    "'split_filename': 'mimiciv_icd10_split.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_pipeline(config=cfg.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/lib/python3.10/site-packages/gensim/models/keyedvectors.py:551: UserWarning: Adding single vectors to a KeyedVectors which grows by one each time can be costly. Consider adding in batches or preallocating to the required size.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "text_encoder = get_text_encoder(\n",
    "    config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรงนี้เปลี่ยน target เป็น int นะ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded transform\n"
     ]
    }
   ],
   "source": [
    "label_transform = get_transform(\n",
    "    config=cfg.label_transform,\n",
    "    targets=data.all_targets,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set TokenSequence, HuggingFaceTokenizer, BOW แต่งเติมส่วนของ padding unknow ให้เรียบร้อย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded transform\n"
     ]
    }
   ],
   "source": [
    "text_transform = get_transform(\n",
    "    config=cfg.text_transform,\n",
    "    texts=data.get_train_documents,\n",
    "    text_encoder=text_encoder,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform text จริง โดยมองเป็น batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.truncate_text(cfg.data.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming text...: 100%|██████████| 31/31 [00:01<00:00, 16.34it/s]\n",
      "Collecting results...: 100%|██████████| 31/31 [00:00<00:00, 4943.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#transform token=>index ตัวเลข เด๋ว train จะถูกผลักออกเป็น vector \n",
    "data.transform_text(text_transform.batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target มีทำ map กลับเป็น int ไว้เลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_classes_per_example': 15.65479481182224,\n",
      " 'average_tokens_per_example': 1596.879217847855,\n",
      " 'num_classes': 7942,\n",
      " 'num_examples': 122278,\n",
      " 'num_test_classes': 7935,\n",
      " 'num_test_examples': 19801,\n",
      " 'num_train_classes': 7939,\n",
      " 'num_train_examples': 89091,\n",
      " 'num_train_tokens': 141971714,\n",
      " 'num_val_classes': 7906,\n",
      " 'num_val_examples': 13386,\n",
      " 'pad_index': 0,\n",
      " 'vocab_size': 62774}\n"
     ]
    }
   ],
   "source": [
    "lookups = get_lookups(\n",
    "    config=cfg.lookup,\n",
    "    data=data,\n",
    "    label_transform=label_transform,\n",
    "    text_transform=text_transform,\n",
    ")\n",
    "\n",
    "# print data info\n",
    "pprint(lookups.data_info)\n",
    "# pprint(lookups.data_info[\"num_classes\"] == len(lookups.code_system2code_indices['icd10_diag'])+len(lookups.code_system2code_indices['icd10_proc']))\n",
    "\n",
    "\n",
    "#สังเกตแค่่ train เท่านั้นหากเราพยายามเปลียน input เพื่อทดสอบ n น้อยๆ ให้ run model ผ่าน ตอน val / test ถูกล็อคไว้หมดแล้ว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ระบุโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VanillaConv(\n",
       "  (embed_drop): Dropout(p=0, inplace=False)\n",
       "  (embed): Embedding(62774, 100, padding_idx=0)\n",
       "  (conv): Conv1d(100, 500, kernel_size=(4,), stride=(1,))\n",
       "  (fc): Linear(in_features=500, out_features=7942, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(\n",
    "    config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 10456842\n"
     ]
    }
   ],
   "source": [
    "# นับจำนวนพารามิเตอร์ทั้งหมด\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# ตรวจสอบจำนวนพารามิเตอร์ในโมเดล\n",
    "num_parameters = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {num_parameters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จัดเตรียม datasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating examples train: 100%|██████████| 89091/89091 [00:06<00:00, 13498.83it/s]\n",
      "Creating examples val: 100%|██████████| 13386/13386 [00:01<00:00, 9592.04it/s]\n",
      "Creating examples test: 100%|██████████| 19801/19801 [00:01<00:00, 14109.64it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets(\n",
    "    config=cfg.dataset,\n",
    "    data=data,\n",
    "    text_transform=text_transform,\n",
    "    label_transform=label_transform,\n",
    "    lookups=lookups,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สามารถปรับ batch Optimize ได้ตรงนี้เลย ตรงนี้เป็นการบังคับเฉพาะให้เฉพาะ train เท่านั้น ถูกควบคุมโดย cfg.dataloader.name\n",
    "\n",
    "set loader มีทั้ง train train_val test val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Train batch size: 8'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Train batch size: 8'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: drop_last=True, dropping last non batch-size batch in every bucket ... \n"
     ]
    }
   ],
   "source": [
    "#ตรงนี้เตรียม batch ให้เรียบร้อยแล้วหละ เดิม #dataset ยังไม่ทำเป็น batch นะ \n",
    "dataloaders = get_dataloaders(config=cfg.dataloader, datasets_dict=datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 1e-05\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = get_optimizer(config=cfg.optimizer, model=model)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรื่องของ batchsize ตำนวนหา gradient กรณี accumulate_grad_batches > 1 แสดงว่ายังไม่ปรับ grad ทันที & Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_grad_batches = int(\n",
    "    max(cfg.dataloader.batch_size / cfg.dataloader.max_batch_size, 1)\n",
    ")\n",
    "num_training_steps = (\n",
    "    math.ceil(len(dataloaders[\"train\"]) / accumulate_grad_batches)\n",
    "    * cfg.trainer.epochs\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(\n",
    "    config=cfg.lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_names: list[str] = [\"train\", \"train_val\", \"val\", \"test\"],\n",
    "\n",
    "splits_with_multiple_code_systems: set[str] = {\"train_val\", \"val\", \"test\"},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'train': {'all': <src.metrics.MetricCollection at 0x7fb6b453ab30>},\n",
       "             'train_val': {'all': <src.metrics.MetricCollection at 0x7fb6b453b880>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7fb6b457fd90>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7fb6b45cc040>},\n",
       "             'val': {'all': <src.metrics.MetricCollection at 0x7fb6b45cc7c0>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7fb6b45ccf40>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7fb6b45cd6c0>},\n",
       "             'test': {'all': <src.metrics.MetricCollection at 0x7fb6b45cded0>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7fb6b45ce650>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7fb6b45cedd0>}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code_system2code_indices => diag proc (ทั้งหมดเลยนะไม่แยก train test)\n",
    "#split2code_indices =>  train train_val val test\n",
    "metric_collections = get_metric_collections(\n",
    "    config=cfg.metrics,\n",
    "    number_of_classes=lookups.data_info[\"num_classes\"],\n",
    "    code_system2code_indices=lookups.code_system2code_indices, # รวมทั้งหมดที่เป็น label diag และ label proc\n",
    "    split2code_indices=lookups.split2code_indices, # label classs แต่ละ กกลุ่มที่แบ่งไป ตาม \n",
    ")\n",
    "metric_collections\n",
    "\n",
    "#ข้างในมี แต่ index ล้วนๆเลยนะ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name: WandbCallback\n",
    "\n",
    "- name: SaveBestModelCallback\n",
    "\n",
    "- name: EarlyStoppingCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.trainer.callbacks.SaveBestModelCallback at 0x7fb6b45cfd60>,\n",
       " <src.trainer.callbacks.EarlyStoppingCallback at 0x7fb6b45cfd00>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = get_callbacks(config=cfg.callbacks)\n",
    "callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Accumulating gradients over 1 batch(es).'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Accumulating gradients over 1 batch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mes\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main/src/trainer/trainer.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.gradient_scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "/root/python/myenv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'experiments/qtsvcsd5'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'experiments/qtsvcsd5'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval = Trainer(\n",
    "    config=cfg,\n",
    "    data=data,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataloaders=dataloaders,\n",
    "    metric_collections=metric_collections, # metric มี 4 กลุ่ม ตอน ใช้ metric จะแยกกล่มใครกล่มมั่นไปแล้ว\n",
    "    callbacks=callbacks,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    lookups=lookups,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    "    experiment_path = Path(cfg.load_model) # ไว้สำหรับ eval \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval output จะเก็บไว้ที่ load_model เลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main/src/trainer/trainer.py:422: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.experiment_path / file_name,map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2525)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Loaded checkpoint from experiments/qtsvcsd5/best_model.pt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Loaded checkpoint from experiments/qtsvcsd5/best_model.pt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Validating on val:   0%|          | 0/105 [00:00<?, ?it/s]/root/python/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch: 6 | Validating on val: 100%|██████████| 105/105 [00:52<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.4726 at DB: 0.2525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Best threshold: 0.2525252401828766'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Best threshold: 0.2525252401828766'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Best result: 0.4726119041442871'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Best result: 0.4726119041442871'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving predictions'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving predictions'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Building dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Building dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding targets'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding targets'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding ids'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding ids'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved predictions in 8.67 seconds'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved predictions in 8.67 seconds'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Validating on test:   0%|          | 0/155 [00:00<?, ?it/s]/root/python/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch: 6 | Validating on test: 100%|██████████| 155/155 [01:07<00:00,  2.28it/s]\n",
      "/root/python/myenv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "if cfg.load_model:\n",
    "    eval.experiment_path = Path(cfg.load_model)\n",
    "eval.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
