{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def remove_pycache(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for d in dirs:\n",
    "            if d == \"__pycache__\":\n",
    "                shutil.rmtree(os.path.join(root, d))\n",
    "\n",
    "# Run the function in your work directory\n",
    "remove_pycache(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 17:16:18.743202: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-14 17:16:21.606022: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-14 17:16:22.426397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2025-03-14 17:16:22.426419: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2025-03-14 17:16:27.162651: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-14 17:16:27.162779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2025-03-14 17:16:27.162787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/tmp/ipykernel_3463/4218327119.py:46: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../../configs\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is not available\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Device: cpu'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Device: cpu'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'CUDA_VISIBLE_DEVICES: [6]'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'CUDA_VISIBLE_DEVICES: \u001b[0m\u001b[32m[\u001b[0m\u001b[32m6\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from hydra import initialize, compose\n",
    "from rich.pretty import pprint\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "\n",
    "from src.data.data_pipeline import data_pipeline\n",
    "from src.factories import (\n",
    "    get_callbacks,\n",
    "    get_dataloaders,\n",
    "    get_datasets,\n",
    "    get_lookups,\n",
    "    get_lr_scheduler,\n",
    "    get_metric_collections,\n",
    "    get_model,\n",
    "    get_optimizer,\n",
    "    get_text_encoder,\n",
    "    get_transform,\n",
    ")\n",
    "from src.trainer.trainer import Trainer\n",
    "from src.utils.seed import set_seed\n",
    "\n",
    "LOGGER = logging.getLogger(name='test')\n",
    "LOGGER.setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "def deterministic() -> None:\n",
    "    \"\"\"Run experiment deterministically. There will still be some randomness in the backward pass of the model.\"\"\"\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":16:8\"\n",
    "\n",
    "    import torch\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "# Clear the global Hydra instance\n",
    "GlobalHydra.instance().clear()\n",
    "#Load configuration\n",
    "\n",
    "initialize(config_path=\"../../configs\")\n",
    "\n",
    "\n",
    "\n",
    "cfg = compose(config_name=\"config\",\n",
    "              overrides=[\n",
    "                  \"experiment=mimiciv_icd10/multi_res_conv.yaml\",\n",
    "                  \"trainer.validate_on_training_data=false\",\n",
    "                  \"callbacks=no_wandb\",\n",
    "                  \"load_model=./experiments/jc1u3c6s\",\n",
    "                  \"trainer.epochs=0\"\n",
    "              ])\n",
    "\n",
    "\n",
    "if cfg.deterministic:\n",
    "    deterministic()\n",
    "else: \n",
    "    import torch\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU is available\")\n",
    "        print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"GPU is not available\")\n",
    "set_seed(cfg.seed)\n",
    "\n",
    "# Check if CUDA_VISIBLE_DEVICES is set\n",
    "if \"CUDA_VISIBLE_DEVICES\" not in os.environ:\n",
    "    if cfg.gpu != -1 and cfg.gpu is not None and cfg.gpu != \"\":\n",
    "     \n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = (\n",
    "            \",\".join([str(gpu) for gpu in cfg.gpu])\n",
    "            if isinstance(cfg.gpu, list)\n",
    "            else str(cfg.gpu)\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pprint(f\"Device: {device}\")\n",
    "pprint(f\"CUDA_VISIBLE_DEVICES: {os.environ['CUDA_VISIBLE_DEVICES']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'seed': 1337, 'deterministic': False, 'gpu': [6], 'name': None, 'debug': False, 'load_model': './experiments/jc1u3c6s', 'data': {'dir': 'files/data/mimiciv_icd10', 'data_filename': 'mimiciv_icd10.feather', 'split_filename': 'mimiciv_icd10_split.feather', 'code_column_names': ['icd10_diag', 'icd10_proc'], 'max_length': 4000}, 'dataset': {'name': 'BaseDataset', 'configs': {}}, 'dataloader': {'max_batch_size': 16, 'batch_size': 16, 'num_workers': 0, 'drop_last': True, 'pin_memory': False, 'batch_sampler': {'name': 'BySequenceLengthSampler', 'configs': {'bucket_boundaries': [400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2600, 3000, 4000]}}}, 'model': {'name': 'MultiResCNN', 'configs': {'kernel_sizes': [3, 5, 9, 15, 19, 25], 'num_filters': 50, 'embed_dropout': 0.2}}, 'text_encoder': {'name': 'Word2Vec', 'file_name': 'word2vec_full.model', 'load_model': True, 'configs': {'min_document_count': 3, 'model_configs': {'vector_size': 100, 'min_count': 0, 'workers': -1, 'epochs': 5}}}, 'trainer': {'epochs': 0, 'validate_on_training_data': False, 'print_metrics': False, 'use_amp': True, 'threshold_tuning': True}, 'optimizer': {'name': 'AdamW', 'configs': {'lr': 0.0005, 'weight_decay': 0.0001}}, 'lr_scheduler': {'name': 'linear', 'configs': {'num_warmup_steps': 2000}}, 'label_transform': {'name': 'OneHotEncoder', 'configs': {}}, 'text_transform': {'name': 'TokenSequence', 'configs': {'min_frequency': 3}}, 'metrics': [{'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5}}, {'name': 'Precision_K', 'configs': {'k': 1}}, {'name': 'Precision_K', 'configs': {'k': 5}}, {'name': 'Precision_K', 'configs': {'k': 8}}, {'name': 'Precision_K', 'configs': {'k': 15}}, {'name': 'Recall_K', 'configs': {'k': 10}}, {'name': 'Recall_K', 'configs': {'k': 15}}, {'name': 'MeanAveragePrecision', 'configs': {}}, {'name': 'PrecisionAtRecall', 'configs': {}}, {'name': 'AUC', 'configs': {'average': 'micro'}}, {'name': 'AUC', 'configs': {'average': 'macro'}}, {'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 1, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 8, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 10, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'MeanAveragePrecision', 'configs': {'filter_codes': False}}, {'name': 'PrecisionAtRecall', 'configs': {'filter_codes': False}}, {'name': 'AUC', 'configs': {'average': 'micro', 'filter_codes': False}}, {'name': 'LossMetric', 'configs': {}}], 'lookup': {'code_description': {'code_desc_path': None, 'code_column': None, 'desc_column': None}}, 'callbacks': [{'name': 'SaveBestModelCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8'}}, {'name': 'EarlyStoppingCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8', 'patience': 10}}], 'data.max_length': 4000}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "พูดถึง vaex\n",
    "\n",
    "'split_filename': 'mimiciv_icd10_split.feather'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_pipeline(config=cfg.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set unsupervise train wordembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embed already exist\n"
     ]
    }
   ],
   "source": [
    "text_encoder = get_text_encoder(\n",
    "    config=cfg.text_encoder, data_dir=cfg.data.dir, texts=data.get_train_documents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ตรงนี้เปลี่ยน target เป็น int นะ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded transform\n"
     ]
    }
   ],
   "source": [
    "label_transform = get_transform(\n",
    "    config=cfg.label_transform,\n",
    "    targets=data.all_targets,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set TokenSequence, HuggingFaceTokenizer, BOW แต่งเติมส่วนของ padding unknow ให้เรียบร้อย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded transform\n"
     ]
    }
   ],
   "source": [
    "text_transform = get_transform(\n",
    "    config=cfg.text_transform,\n",
    "    texts=data.get_train_documents,\n",
    "    text_encoder=text_encoder,\n",
    "    load_transform_path=cfg.load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranform text จริง โดยมองเป็น batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.truncate_text(cfg.data.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming text...: 100%|██████████| 13/13 [01:25<00:00,  6.58s/it]\n"
     ]
    }
   ],
   "source": [
    "#transform token=>index ตัวเลข เด๋ว train จะถูกผลักออกเป็น vector \n",
    "data.transform_text(text_transform.batch_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target มีทำ map กลับเป็น int ไว้เลย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_classes_per_example': 15.65479481182224,\n",
      " 'average_tokens_per_example': 1596.879217847855,\n",
      " 'num_classes': 7942,\n",
      " 'num_examples': 122278,\n",
      " 'num_test_classes': 7935,\n",
      " 'num_test_examples': 19801,\n",
      " 'num_train_classes': 7939,\n",
      " 'num_train_examples': 89091,\n",
      " 'num_train_tokens': 141971714,\n",
      " 'num_val_classes': 7906,\n",
      " 'num_val_examples': 13386,\n",
      " 'pad_index': 0,\n",
      " 'vocab_size': 62774}\n"
     ]
    }
   ],
   "source": [
    "lookups = get_lookups(\n",
    "    config=cfg.lookup,\n",
    "    data=data,\n",
    "    label_transform=label_transform,\n",
    "    text_transform=text_transform,\n",
    ")\n",
    "\n",
    "# print data info\n",
    "pprint(lookups.data_info)\n",
    "# pprint(lookups.data_info[\"num_classes\"] == len(lookups.code_system2code_indices['icd10_diag'])+len(lookups.code_system2code_indices['icd10_proc']))\n",
    "\n",
    "\n",
    "#สังเกตแค่่ train เท่านั้นหากเราพยายามเปลียน input เพื่อทดสอบ n น้อยๆ ให้ run model ผ่าน ตอน val / test ถูกล็อคไว้หมดแล้ว"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ระบุโมเดล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained embeddings...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiResCNN(\n",
       "  (embed_drop): Dropout(p=0.2, inplace=False)\n",
       "  (embed): Embedding(62774, 100, padding_idx=0)\n",
       "  (convs): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(5,), stride=(1,), padding=(2,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(15,), stride=(1,), padding=(7,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Conv1d(100, 100, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
       "      (1): Tanh()\n",
       "      (2): ResidualBlock(\n",
       "        (left): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): Tanh()\n",
       "          (3): Conv1d(50, 50, kernel_size=(25,), stride=(1,), padding=(12,), bias=False)\n",
       "          (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (1): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (channels): ModuleList()\n",
       "  (attention): CAMLAttention(\n",
       "    (first_linear): Linear(in_features=300, out_features=7942, bias=True)\n",
       "    (second_linear): Linear(in_features=300, out_features=7942, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(\n",
    "    config=cfg.model, data_info=lookups.data_info, text_encoder=text_encoder\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จัดเตรียม datasset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating examples train: 100%|██████████| 89091/89091 [00:05<00:00, 16566.11it/s]\n",
      "Creating examples val: 100%|██████████| 13386/13386 [00:01<00:00, 11797.51it/s]\n",
      "Creating examples test: 100%|██████████| 19801/19801 [00:01<00:00, 14397.26it/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = get_datasets(\n",
    "    config=cfg.dataset,\n",
    "    data=data,\n",
    "    text_transform=text_transform,\n",
    "    label_transform=label_transform,\n",
    "    lookups=lookups,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สามารถปรับ batch Optimize ได้ตรงนี้เลย ตรงนี้เป็นการบังคับเฉพาะให้เฉพาะ train เท่านั้น ถูกควบคุมโดย cfg.dataloader.name\n",
    "\n",
    "set loader มีทั้ง train train_val test val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Train batch size: 16'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Train batch size: 16'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: drop_last=True, dropping last non batch-size batch in every bucket ... \n"
     ]
    }
   ],
   "source": [
    "#ตรงนี้เตรียม batch ให้เรียบร้อยแล้วหละ เดิม #dataset ยังไม่ทำเป็น batch นะ \n",
    "dataloaders = get_dataloaders(config=cfg.dataloader, datasets_dict=datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaders[\"train\"].dataset.text_transform.save('./')\n",
    "# dataloaders[\"train\"].dataset.label_transform.save('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdamW (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.0005\n",
       "    maximize: False\n",
       "    weight_decay: 0.0001\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = get_optimizer(config=cfg.optimizer, model=model)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เรื่องของ batchsize ตำนวนหา gradient กรณี accumulate_grad_batches > 1 แสดงว่ายังไม่ปรับ grad ทันที & Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulate_grad_batches = int(\n",
    "    max(cfg.dataloader.batch_size / cfg.dataloader.max_batch_size, 1)\n",
    ")\n",
    "num_training_steps = (\n",
    "    math.ceil(len(dataloaders[\"train\"]) / accumulate_grad_batches)\n",
    "    * cfg.trainer.epochs\n",
    ")\n",
    "lr_scheduler = get_lr_scheduler(\n",
    "    config=cfg.lr_scheduler,\n",
    "    optimizer=optimizer,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split_names: list[str] = [\"train\", \"train_val\", \"val\", \"test\"],\n",
    "\n",
    "splits_with_multiple_code_systems: set[str] = {\"train_val\", \"val\", \"test\"},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'train': {'all': <src.metrics.MetricCollection at 0x7f2082855f90>},\n",
       "             'train_val': {'all': <src.metrics.MetricCollection at 0x7f20828574f0>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f2082693f10>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f2082691090>},\n",
       "             'val': {'all': <src.metrics.MetricCollection at 0x7f2082691540>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f20826bc730>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f20826bceb0>},\n",
       "             'test': {'all': <src.metrics.MetricCollection at 0x7f20826bd6c0>,\n",
       "              'icd10_diag': <src.metrics.MetricCollection at 0x7f20826bde40>,\n",
       "              'icd10_proc': <src.metrics.MetricCollection at 0x7f20826be5c0>}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code_system2code_indices => diag proc (ทั้งหมดเลยนะไม่แยก train test)\n",
    "#split2code_indices =>  train train_val val test\n",
    "metric_collections = get_metric_collections(\n",
    "    config=cfg.metrics,\n",
    "    number_of_classes=lookups.data_info[\"num_classes\"],\n",
    "    code_system2code_indices=lookups.code_system2code_indices, # รวมทั้งหมดที่เป็น label diag และ label proc\n",
    "    split2code_indices=lookups.split2code_indices, # label classs แต่ละ กกลุ่มที่แบ่งไป ตาม \n",
    ")\n",
    "metric_collections\n",
    "\n",
    "#ข้างในมี แต่ index ล้วนๆเลยนะ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name: WandbCallback\n",
    "\n",
    "- name: SaveBestModelCallback\n",
    "\n",
    "- name: EarlyStoppingCallback\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.trainer.callbacks.SaveBestModelCallback at 0x7f2082857820>,\n",
       " <src.trainer.callbacks.EarlyStoppingCallback at 0x7f20826bf520>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = get_callbacks(config=cfg.callbacks)\n",
    "callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 1337, 'deterministic': False, 'gpu': [6], 'name': None, 'debug': False, 'load_model': './experiments/jc1u3c6s', 'data': {'dir': 'files/data/mimiciv_icd10', 'data_filename': 'mimiciv_icd10.feather', 'split_filename': 'mimiciv_icd10_split.feather', 'code_column_names': ['icd10_diag', 'icd10_proc'], 'max_length': 4000}, 'dataset': {'name': 'BaseDataset', 'configs': {}}, 'dataloader': {'max_batch_size': 16, 'batch_size': 16, 'num_workers': 0, 'drop_last': True, 'pin_memory': False, 'batch_sampler': {'name': 'BySequenceLengthSampler', 'configs': {'bucket_boundaries': [400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2200, 2600, 3000, 4000]}}}, 'model': {'name': 'MultiResCNN', 'configs': {'kernel_sizes': [3, 5, 9, 15, 19, 25], 'num_filters': 50, 'embed_dropout': 0.2}}, 'text_encoder': {'name': 'Word2Vec', 'file_name': 'word2vec_full.model', 'load_model': True, 'configs': {'min_document_count': 3, 'model_configs': {'vector_size': 100, 'min_count': 0, 'workers': -1, 'epochs': 5}}}, 'trainer': {'epochs': 0, 'validate_on_training_data': False, 'print_metrics': False, 'use_amp': True, 'threshold_tuning': True}, 'optimizer': {'name': 'AdamW', 'configs': {'lr': 0.0005, 'weight_decay': 0.0001}}, 'lr_scheduler': {'name': 'linear', 'configs': {'num_warmup_steps': 2000}}, 'label_transform': {'name': 'OneHotEncoder', 'configs': {}}, 'text_transform': {'name': 'TokenSequence', 'configs': {'min_frequency': 3}}, 'metrics': [{'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5}}, {'name': 'Precision_K', 'configs': {'k': 1}}, {'name': 'Precision_K', 'configs': {'k': 5}}, {'name': 'Precision_K', 'configs': {'k': 8}}, {'name': 'Precision_K', 'configs': {'k': 15}}, {'name': 'Recall_K', 'configs': {'k': 10}}, {'name': 'Recall_K', 'configs': {'k': 15}}, {'name': 'MeanAveragePrecision', 'configs': {}}, {'name': 'PrecisionAtRecall', 'configs': {}}, {'name': 'AUC', 'configs': {'average': 'micro'}}, {'name': 'AUC', 'configs': {'average': 'macro'}}, {'name': 'F1Score', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'F1Score', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Recall', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'micro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'FPR', 'configs': {'average': 'macro', 'threshold': 0.5, 'filter_codes': False}}, {'name': 'ExactMatchRatio', 'configs': {'threshold': 0.5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 1, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 5, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 8, 'filter_codes': False}}, {'name': 'Precision_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 10, 'filter_codes': False}}, {'name': 'Recall_K', 'configs': {'k': 15, 'filter_codes': False}}, {'name': 'MeanAveragePrecision', 'configs': {'filter_codes': False}}, {'name': 'PrecisionAtRecall', 'configs': {'filter_codes': False}}, {'name': 'AUC', 'configs': {'average': 'micro', 'filter_codes': False}}, {'name': 'LossMetric', 'configs': {}}], 'lookup': {'code_description': {'code_desc_path': None, 'code_column': None, 'desc_column': None}}, 'callbacks': [{'name': 'SaveBestModelCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8'}}, {'name': 'EarlyStoppingCallback', 'configs': {'split': 'val', 'target': 'all', 'metric': 'precision@8', 'patience': 10}}], 'data.max_length': 4000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Accumulating gradients over 1 batch(es).'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Accumulating gradients over 1 batch\u001b[0m\u001b[32m(\u001b[0m\u001b[32mes\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main/src/trainer/trainer.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.gradient_scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)\n",
      "/root/python/myenv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/tmp/tmp5e6b4rm0'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/tmp/tmp5e6b4rm0'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    config=cfg,\n",
    "    data=datasets,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    dataloaders=dataloaders,\n",
    "    metric_collections=metric_collections, # metric มี 4 กลุ่ม ตอน ใช้ metric จะแยกกล่มใครกล่มมั่นไปแล้ว\n",
    "    callbacks=callbacks,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    lookups=lookups,\n",
    "    accumulate_grad_batches=accumulate_grad_batches,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train  ตรงส่วนนี้จะระบุว่าไฟล์ข้อมูลทั้งหมดจะถูกวางไว้ที่ไหนเลย\n",
    "\n",
    "ตอน validate จะสืบหา f1 ที่ดีที่สด "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/python/myenv/medical-coding-reproducibility-main/src/trainer/trainer.py:422: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(self.experiment_path / file_name,map_location=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4242)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Loaded checkpoint from experiments/jc1u3c6s/best_model.pt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Loaded checkpoint from experiments/jc1u3c6s/best_model.pt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Validating on val:   0%|          | 0/837 [00:00<?, ?it/s]/root/python/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch: 18 | Validating on val: 100%|██████████| 837/837 [08:12<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.5668 at DB: 0.4242\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Best threshold: 0.42424243688583374'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Best threshold: 0.42424243688583374'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Best result: 0.5667663812637329'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Best result: 0.5667663812637329'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving predictions'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving predictions'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Building dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Building dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding targets'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding targets'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding ids'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding ids'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved predictions in 6.42 seconds'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved predictions in 6.42 seconds'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Validating on test:   0%|          | 0/1238 [00:00<?, ?it/s]/root/python/myenv/lib/python3.10/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "Epoch: 18 | Validating on test: 100%|██████████| 1238/1238 [07:40<00:00,  2.69it/s]\n",
      "/root/python/myenv/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving predictions'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving predictions'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Building dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Building dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding targets'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding targets'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Adding ids'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Adding ids'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saving dataframe'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saving dataframe'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved predictions in 8.87 seconds'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved predictions in 8.87 seconds'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved checkpoint to experiments/jc1u3c6s/final_model.pt'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved checkpoint to experiments/jc1u3c6s/final_model.pt'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved retrieval to experiments/jc1u3c6s/train_targets.feather'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved retrieval to experiments/jc1u3c6s/train_targets.feather'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved retrieval to experiments/jc1u3c6s/val_targets.feather'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved retrieval to experiments/jc1u3c6s/val_targets.feather'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'Saved retrieval to experiments/jc1u3c6s/test_targets.feather'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'Saved retrieval to experiments/jc1u3c6s/test_targets.feather'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if cfg.load_model:\n",
    "    trainer.experiment_path = Path(cfg.load_model)\n",
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
